# Brain Dump - User Journey (v2)

## Context

The web tool I'm building uses a Omega S API endpoint as inputs and produces QuickStatements code to import the data from the inputs API data to Wikidata. The Omega S API endpoint uses JSONLD (linked Data). This input should be transformed along the route to conform to Wikidata. I am trying to smooth out the steps a user will go through to perform this data transformation whilst keeping it clear, simple and easy to use.

## Process Brain Dump

Okay, this is my brain dump. The user loads the tool either through a pre-populated URL with parameters defining where the data comes from either from a API endpoint or from a front-end URL that can be translated to an API endpoint by the tool. Then the next step will be to confirm so and the arrival so either it's a new project or it's loading a previous project. Or this step is skipped because the URL parameters will help you skip this step and go directly through which I call for now step one, which is input. There you can put input by hand a front end link of a Omega S website or a API endpoint of omega s there should be some parameters there for the user where the user can choose change some settings of the API Endpoints and some parameters and the identified API endpoint based on the front end link should be displayed there and also the user should be told how many items have been identified. At this API endpoints, clarifying clarifying How big this project will become for the user. Then in a potential step two existing mappings can be selected. So this is this is a bigger step, I guess, with substeps, but I don't know yet how they be called or how categorized. But the user should be able to select existing mappings To facilitate the process of creating the mapping. The user can also decide not to select the mapping. I forgot to tell that during the existing mapping selection it should also be possible to select an entity schema And maybe it should be possible to select both a mapping and schema to combine those and the knowledge of both for later steps. Then a next step is whether user looks at the imported mapping and schema and or schema and checks if all the Properties from the imported link data are correctly mapped to Wikidata items and this can be refined or completed or elaborated. I don't know what the proper word for this is. And this is also the location where it can also just be confirmed that it's good as is. Just afterwards, the user should also have the possibility to add new properties. and these new properties can have for example fixed values and or it could be a new property based on splitting up values from a specific linked data property with several values. In some use cases for context, in some use cases imported data have a property, linked data property, with several values which in Wikidata are separated. Therefore, the user should have this possibility to create new properties and either add a val fixed value or split up an existing property values. So in some way, that would be a situation where you have a link data property mapped to two different or separate Wikidata properties. This would be the logical way of explaining it. Therefore, the user should also know which properties have multiple values per item, helping them identify which one should be split or mapped to several Wikidata properties. The next step would be to add settings to the Wikidata properties for later use in the reconciliation. things like what type of value is expected meaning could be a QID or meaning a Wikidata item, could be a string, could be a date, could be some things like that. And It should also be added if a property has expected qualifiers qualifying the language of the stream for example or Other logical qualifiers for that property. And also, if that property expects a reference. This step where the property settings are defined could also be pre-populated based on the requirements described on the property pages on Wikidata. Wikidata properties have requirements and things they have to adhere to, throwing errors or warning the user otherwise if they don't comply. And these settings could be used to help User fill in the right property settings. Then there should be a step for the user to identify and coupling or connecting references to the relevant properties. References can be for an entire item or for a specific property in that item. and their origin can be based on the front-end link possibly provided In step one, the input or actually the the URL parameters. References can be reused within the same item or be specific Statements (linking a value and a property and an item).References are always unique to items. References can then be coupled to either an item or a specific item property. If a referens is coupled to the entire item, it can be Toggled for every property in that item. Then the user could go to a new step and I don't know how to call this yet. But it should be something like value configuration and that is where values Can be pre-processed This step should look at values per property. For example, If a linked data input property is linked to multiple Wikidata properties This is the step where the user should be able to try to identify Types of values from the input data, from the link data. to go to one Wikidata property or another and in this step the user might also be able to do things like Identifying identifiers like VIAF or GeoNames, and more. This is also the step where the user might. Somewhat change the Values of a property such as using find and replace Or simple remove thing Of bits of strings. This step might not be completely thought out and might change in the future. The next step is item reconciliation Meaning checking if items already exist on Wikidata. Meaning the user is not looking, or the system is not looking at values of that item, but the entire item. coming from linked data and trying to see if it already exists on Wikidata. This uses the reconciliation API And the outcome of these steps should be that it is known if the item is new or if it already exists on Wikidata. And if it already exists on Wikidata we should pull the information from Wikidata and Let the chooser let the user choose which information is Leading, meaning if the existing Wikidata information is Generally leading, or if the Existing or the new input data from The linked data is the lead And in that case the user at some point maybe in this step needs to decide if it adds the statement to the Wikidata item, to that property of the Wikidata item, or if it replaces These data fields. This can also be a step where the user says that if an item already exists For these items a property will be ignored because the values already exist. The next step is the reconciliation of values for each item. Maybe here also the User could choose if the item statement, if the statement replaces Or complements wiki data if it does not replace it and is ignored, there should still be the possibility for the user to Add the reference from this data to the existing statement. In this reconciliation of the value step, the User should be assisting the reconciliation API in selecting The correct values for every value. Meaning sometimes the reconciliation API has a 100% match. In that case, it's probably good, but the user should be able to remove the match and find a suitable value And in the case of a non-hundred percent match, the user should be able to pick one from The suggested values from the reconciliation API or select a new one by hand. And if no reconciliation is found, the user should add it by hand. Adding a value should be constrained by the expected value type coming from the property settings. and should include also an expected qualifier value, for example a language string. A string language value qualifier. And in the next step, once the reconciliation is completed Ignored values in the reconciliation step will be ignored in the further process. avoiding adding values that are not humanly controlled tested confirmed. The next step is called results quality control, meaning there the user can read all the Defined statements, meaning item property value. With optional qualifiers, references, and that sort of stuff. There the user can see how it would look like on Wikidata, all the statements and Check if this is the intended result. Then the next step will be the export to quick statements. Meaning the statements defined in this process will be translated, rewritten in the right format for quick statements to accept them and the user will be able to click on a link to go to the quick statements tool and import it there or download a text file with all the statements in there. It should also be the moment the user is reminded to save the project. Again to make sure it can be reused. In a later situation, in general user experience elements are that the user can always Save and load projects and The user is never logged in, there is no login. Therefore, if the user by accident reloads the page or comes back later the browser from its I think it's called browser cache, but I'm not sure will propose to reload the last Project instead of starting fresh.

## Complimentary Brain Dump

Okay, here are a few more details and observations. In the mapping In the mapping confirmations tab there should always be a label property, which is not an official property on Wikidata, but it should be there in the property mapping, such that you can map a value to it. from the linked data values. The same could be with description, although it's fine if that is Is kept empty. And in the next step, where you add a fixed values, it should always force the user to add either a instance of or a subclass of value as a fixed value And that's probably in this use case always going to be an instance of value. And split properties such that you have one linked data property from the input that matches to several Wikidata properties. That can be two, or it can be one, two, three, or more. So it can be more than two. The property settings, Wikidata property settings, should be pre-populated by both searches on the requirements of the properties on wiki data and also the entity scheme. For example, the entity schema can say if a reference is expected or required. The setting step is only to indicate if qualifiers or also monolingual text language selection actually or monolingual string language selection. Sorry, let me recap that. So you have value type qualifier monolingual string language and references And the settings should indicate if they are expected, maybe also required, or not at all. In step afterwards, also in reference identification and coupling there It's also nice to remember that every specific reference can only be linked to one specific item. This does need not need to be enforced, but can be used as a logic in the user interface for the design. And the same reference can be used multiple times for different properties in the same item. But would logically not be used in other items. The user can, however, by hand add them separately. the user so wishes and you have references that are the same Or actually what's important to know for the references is that they They have respective values for each item. So you can have like one reference Collection, I guess, with a respective value for each Item during this process. So there are often also collections. Let me see. Yeah, and the next step also maybe more logical not to call value configuration, but data cleaning or something like that. I was thinking of a find and replace. a find and remove, which is remove and maybe for power users also a regular expression way of handling manipulating the string. So that's basically string manipulation which will not be needed for items or properties with an expected value of Wikidata item, but more of for the properties with expected strings and the property definitions on wikidata also include regex to check if the values are correct. And in this step it will be very relevant to show that if the regex of Wikidata Confirms that the string is correct or not. This step should be more of a property centric step for the whole for all values of the same property instead of a situation where you do individual edits for each value. The VIAF and the geonames are actually not relevant in this step. However, they could be used here or somewhere else in this tool. to help the reconciliation because they are never about the item, they are always about a value and often referring to a second source for the value. So this would help in a reconciliation step. Which is also interesting is in the item reconciliation which could actually also be you called Duplicate search is searching for duplicate items, items that already exist that you're trying to add as new items. This step, yeah, well, as has been said, should determine if the item is new and if the item already or if the item already exists. This is a Item-centric process and If it already exists, there are basically four options as I see them right now. Ignore the new value, replace the Wikidata value with the new value. add the new value to the Wikidata value, such that there are two values for the same property in Wikidata. or merge and that would be mostly in case you have a you have the same value here as on Wikidata, but you have a source or reference that can be reused. And This could be default applied to all Already existing items this choice. And this wall And In a reconciliation of values, there should be an option for the user to edit a specific string in a value because that's relevant. There should also be a option for reconciling all the similar values such that you have a value And if it's the same value for all the if the same value happens more times and reconcile for all of them, if it's the same. And also give the option to add monolingual text language there specifically for each value.